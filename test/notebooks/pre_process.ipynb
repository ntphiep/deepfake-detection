{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nMI7CYxcyiUB"
      },
      "source": [
        "Before running the file Upload all your data set on your goole drive in a zip format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YjtnZQkTu6tX"
      },
      "outputs": [],
      "source": [
        "#Mount our google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install face_recognition torch torchvision\n",
        "!mkdir '/content/drive/My Drive/FF_REAL_Face_only_data'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "f4y_fGlmur4v"
      },
      "outputs": [],
      "source": [
        "#before running this please change the RUNTIME to GPU (Runtime -> Change runtime type -> set harware accelarotor as GPU)\n",
        "#download and unzip the data from google drive Colab environment\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "#use only file id of the link\n",
        "#Note: Below link is just an example, Not an actual link. Actual Links are in ReadMe file\n",
        "#https://drive.google.com/file/d/1ubvKLzBDe5i1acxgGUK6ObeNBYCKUS07/view?usp=sharing\n",
        "url = '1ubvKLzBDe5i1acxgGUK6ObeNBYCKUS07'\n",
        "gdd.download_file_from_google_drive(file_id=url, dest_path='./data.zip', unzip=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1f40EeRuvAkO"
      },
      "outputs": [],
      "source": [
        "# Get the average frame count \n",
        "import json\n",
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import copy\n",
        "\n",
        "# Change the path accordingly\n",
        "video_files = glob.glob('/content/Real videos/*.mp4')\n",
        "#video_files1 =  glob.glob('/content/dfdc_train_part_0/*.mp4')\n",
        "#video_files += video_files1\n",
        "\n",
        "frame_count = []\n",
        "for video_file in video_files:\n",
        "\tcap = cv2.VideoCapture(video_file)\n",
        "\tif(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) < 150):\n",
        "\t\tvideo_files.remove(video_file)\n",
        "\t\tcontinue\n",
        "\tframe_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "  \n",
        "print(\"Frames: \", frame_count)\n",
        "print(\"Total number of videos: \", len(frame_count))\n",
        "print(\"Average frame per video:\", np.mean(frame_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "U92Ovn3JvV52"
      },
      "outputs": [],
      "source": [
        "# Extract frame\n",
        "def frame_extract(path):\n",
        "\tvidObj = cv2.VideoCapture(path) \n",
        "\tsuccess = 1\n",
        "\twhile success:\n",
        "\t\tsuccess, image = vidObj.read()\n",
        "\t\tif success: yield image\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import face_recognition\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "\n",
        "# process the frames\n",
        "def create_face_videos(path_list,out_dir):\n",
        "    already_present_count = glob.glob(out_dir + '*.mp4')\n",
        "    print(\"No of videos already present \", len(already_present_count))\n",
        "    \n",
        "    for path in tqdm(path_list):\n",
        "        out_path = os.path.join(out_dir, path.split('/')[-1])\n",
        "        file_exists = glob.glob(out_path)\n",
        "        if(len(file_exists) != 0):\n",
        "            print(\"File Already exists: \", out_path)\n",
        "            continue\n",
        "        \n",
        "        frames = []\n",
        "        out = cv2.VideoWriter(out_path,cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), 30, (112, 112))\n",
        "        \n",
        "        for idx,frame in enumerate(frame_extract(path)):\n",
        "            if idx <= 150:\n",
        "                frames.append(frame)\n",
        "                if len(frames) == 4:\n",
        "                    faces = face_recognition.batch_face_locations(frames)\n",
        "                    for i,face in enumerate(faces):\n",
        "                        if len(face) != 0:top, right, bottom, left = face[0]\n",
        "                            \n",
        "                        try: out.write(cv2.resize(frames[i][top:bottom, left:right, :], (112,112)))\n",
        "                        except: pass\n",
        "                    frames = []\n",
        "                    \n",
        "        try: del top, right, bottom, left\n",
        "        except: pass\n",
        "        out.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sF5qiWGLvei-"
      },
      "outputs": [],
      "source": [
        "create_face_videos(video_files,'/content/drive/My Drive/FF_REAL_Face_only_data/')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "preprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
